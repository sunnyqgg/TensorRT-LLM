#!/usr/bin/env python3
"""
è¯»å–å’ŒéªŒè¯ KV cache dump æ•°æ®çš„å·¥å…·è„šæœ¬
"""
from pathlib import Path

import numpy as np


def load_kv_token(token_idx,
                  dump_dir="./dump_data",
                  num_heads=8,
                  head_dim=128,
                  dtype=np.float16):
    """
    åŠ è½½æŒ‡å®š token çš„ K å’Œ V cache æ•°æ®

    Args:
        token_idx: token ç´¢å¼•
        dump_dir: dump æ•°æ®ç›®å½•
        num_heads: KV head æ•°é‡
        head_dim: æ¯ä¸ª head çš„ç»´åº¦
        dtype: æ•°æ®ç±»å‹ (np.float16, np.int8, np.uint8 ç­‰)

    Returns:
        (k_data, v_data): å½¢çŠ¶ä¸º [num_heads, head_dim] çš„ numpy æ•°ç»„
    """
    k_path = Path(dump_dir) / f"key_token_idx_[{token_idx}].bin"
    v_path = Path(dump_dir) / f"v_key_token_idx_[{token_idx}].bin"

    if not k_path.exists():
        raise FileNotFoundError(f"K cache file not found: {k_path}")
    if not v_path.exists():
        raise FileNotFoundError(f"V cache file not found: {v_path}")

    # è¯»å–æ•°æ®
    k_data = np.fromfile(k_path, dtype=dtype)
    v_data = np.fromfile(v_path, dtype=dtype)

    # Reshape ä¸º [num_heads, head_dim]
    k_data = k_data.reshape(num_heads, head_dim)
    v_data = v_data.reshape(num_heads, head_dim)

    return k_data, v_data


def load_all_kv_tokens(total_tokens=61,
                       dump_dir="./dump_data",
                       num_heads=8,
                       head_dim=128,
                       dtype=np.float16):
    """
    åŠ è½½æ‰€æœ‰ token çš„ KV cache æ•°æ®

    Returns:
        (all_k, all_v): å½¢çŠ¶ä¸º [total_tokens, num_heads, head_dim] çš„ numpy æ•°ç»„
    """
    all_k = []
    all_v = []

    for token_idx in range(total_tokens):
        try:
            k_data, v_data = load_kv_token(token_idx, dump_dir, num_heads,
                                           head_dim, dtype)
            all_k.append(k_data)
            all_v.append(v_data)
            print(
                f"âœ“ Loaded token {token_idx:3d}: K shape={k_data.shape}, V shape={v_data.shape}"
            )
        except FileNotFoundError as e:
            print(f"âœ— Token {token_idx}: {e}")
            break

    if not all_k:
        return None, None

    all_k = np.stack(all_k, axis=0)  # [total_tokens, num_heads, head_dim]
    all_v = np.stack(all_v, axis=0)

    return all_k, all_v


def load_q_buffer(dump_dir="./dump_data",
                  num_tokens=25,
                  num_heads=32,
                  head_dim=128,
                  dtype=np.float16):
    """åŠ è½½ Q buffer"""
    q_path = Path(dump_dir) / "q_buffer.bin"
    if not q_path.exists():
        raise FileNotFoundError(f"Q buffer file not found: {q_path}")

    q_data = np.fromfile(q_path, dtype=dtype)
    q_data = q_data.reshape(num_tokens, num_heads, head_dim)
    return q_data


def load_custom_mask(dump_dir="./dump_data", mask_shape=(2, 128, 128)):
    """åŠ è½½ custom mask"""
    mask_path = Path(dump_dir) / "custom_mask.bin"
    if not mask_path.exists():
        raise FileNotFoundError(f"Custom mask file not found: {mask_path}")

    mask_data = np.fromfile(mask_path, dtype=np.int32)
    mask_data = mask_data.reshape(mask_shape)
    return mask_data


def verify_kv_cache(dump_dir="./dump_data",
                    total_tokens=61,
                    num_heads=8,
                    head_dim=128):
    """éªŒè¯ KV cache dump æ•°æ®"""
    print("=" * 80)
    print("éªŒè¯ KV Cache Dump æ•°æ®")
    print("=" * 80)

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    dump_path = Path(dump_dir)
    if not dump_path.exists():
        print(f"âŒ Dump ç›®å½•ä¸å­˜åœ¨: {dump_dir}")
        return False

    print(f"ğŸ“ Dump ç›®å½•: {dump_dir}")
    print(f"ğŸ¯ é¢„æœŸ token æ•°é‡: {total_tokens}")
    print(f"ğŸ¯ é¢„æœŸ KV head æ•°é‡: {num_heads}")
    print(f"ğŸ¯ é¢„æœŸæ¯ä¸ª head ç»´åº¦: {head_dim}")
    print()

    # åŠ è½½æ‰€æœ‰ KV cache
    print("æ­£åœ¨åŠ è½½ KV cache æ•°æ®...")
    all_k, all_v = load_all_kv_tokens(total_tokens,
                                      dump_dir,
                                      num_heads,
                                      head_dim,
                                      dtype=np.float16)

    if all_k is None:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½• KV cache æ•°æ®")
        return False

    print()
    print(f"âœ… æˆåŠŸåŠ è½½ {len(all_k)} ä¸ª token çš„ KV cache")
    print(f"   K cache shape: {all_k.shape}")
    print(f"   V cache shape: {all_v.shape}")

    # ç»Ÿè®¡ä¿¡æ¯
    print()
    print("ğŸ“Š K Cache ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   Min: {all_k.min():.6f}")
    print(f"   Max: {all_k.max():.6f}")
    print(f"   Mean: {all_k.mean():.6f}")
    print(f"   Std: {all_k.std():.6f}")

    print()
    print("ğŸ“Š V Cache ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   Min: {all_v.min():.6f}")
    print(f"   Max: {all_v.max():.6f}")
    print(f"   Mean: {all_v.mean():.6f}")
    print(f"   Std: {all_v.std():.6f}")

    # å°è¯•åŠ è½½ Q buffer
    print()
    try:
        q_data = load_q_buffer(dump_dir)
        print(f"âœ… Q buffer shape: {q_data.shape}")
        print(
            f"   Min: {q_data.min():.6f}, Max: {q_data.max():.6f}, Mean: {q_data.mean():.6f}"
        )
    except FileNotFoundError as e:
        print(f"âš ï¸  Q buffer: {e}")

    # å°è¯•åŠ è½½ custom mask
    print()
    try:
        mask_data = load_custom_mask(dump_dir)
        print(f"âœ… Custom mask shape: {mask_data.shape}")
        print(f"   Min: {mask_data.min()}, Max: {mask_data.max()}")
    except FileNotFoundError as e:
        print(f"âš ï¸  Custom mask: {e}")

    print()
    print("=" * 80)
    print("âœ… éªŒè¯å®Œæˆ")
    print("=" * 80)

    return True


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="è¯»å–å’ŒéªŒè¯ KV cache dump æ•°æ®")
    parser.add_argument("--dump_dir",
                        type=str,
                        default="./dump_data",
                        help="Dump æ•°æ®ç›®å½•")
    parser.add_argument("--total_tokens",
                        type=int,
                        default=61,
                        help="æ€» token æ•°é‡")
    parser.add_argument("--num_heads", type=int, default=8, help="KV head æ•°é‡")
    parser.add_argument("--head_dim", type=int, default=128, help="æ¯ä¸ª head çš„ç»´åº¦")
    parser.add_argument("--token_idx",
                        type=int,
                        default=None,
                        help="åªåŠ è½½æŒ‡å®š token (å¯é€‰)")

    args = parser.parse_args()

    if args.token_idx is not None:
        # åªåŠ è½½æŒ‡å®š token
        print(f"åŠ è½½ token {args.token_idx}...")
        k_data, v_data = load_kv_token(args.token_idx, args.dump_dir,
                                       args.num_heads, args.head_dim)
        print(f"K cache shape: {k_data.shape}")
        print(f"V cache shape: {v_data.shape}")
        print(f"\nK cache (head 0, first 8 elements):\n{k_data[0, :8]}")
        print(f"\nV cache (head 0, first 8 elements):\n{v_data[0, :8]}")
    else:
        # éªŒè¯æ‰€æœ‰æ•°æ®
        verify_kv_cache(args.dump_dir, args.total_tokens, args.num_heads,
                        args.head_dim)


if __name__ == "__main__":
    main()
